\subsection{Funktionsweise}\label{s:cfs_fktweise}

%hier sollten wir mal reinschauen:
%https://www.ece.ubc.ca/~sasha/papers/eurosys16-final29.pdf
%HAB AUCH SCHON WAS GEFUNDEN...ABER SCHAUE ICH MIR AUCH MAL AN...

%Das Ziel eines  Completely-Fair-Schedulers{} soll es sein, eine gute Annäherung an das Verhalten eines perfekten Multitasking-Prozessor zu errreichen.
Das Ziel eines  Completely-Fair-Schedulers{} soll es sein, eine faire Aufteilung der Ressource Prozessor unter einer Menge von ausführbaren Prozessen zu erreichen.


%Ein perfekter Multi\-tasking-Prozessor würde jedem Prozess immer ein perfektes $1/n$ Verhältnis zuweisen, wobei $n$ die Menge aller Prozesse darstellt."
Im einfachsten Fall, wenn keine Prioritäten unter den Prozessen vergeben werden, ist eine perfekte Aufteilung der Ressource dann gegeben, wenn zu jedem Zeitpunkt jeder Prozess immer eine Zuteilung im Verhältnis $1/n$ erhält, wobei $n$ die Menge aller Prozesse darstellt.
Bei zwei laufenden Prozessen heißt das, dass beide Prozesse zeitgleich mit jeweils 50 Prozent der Prozessorressource arbeiten. Dies ist in der Praxis allerdings nicht möglich, da jeder Prozessor immer nur eine Aufgabe zu einem Zeitpunkt bearbeiten kann.

Unter Linux und UNIX-artigen System werden daher den beiden Prozessen Zeitscheiben zugeordnet und es findet eine sequentielle Abarbeitung statt. Anschließend werden die Prozesse abwechselnd mit jeweils 100 Prozent Prozessorzuteilung entsprechend ihrer Zeitscheibe verarbeitet.

%Um mit diesem Prinzip eine Annäherung an einen perfekten Multitasking-Prozessor zu erreichen, müsste man die Zuteilung für jeden Prozess in unendlich kleine Zeitscheiben zerlegen und alternierend dem Prozessor zuweisen.
Je kleiner die Zeitscheiben gewählt werden, desto mehr wird ein nahezu zeitgleiches Abarbeiten der anstehenden Prozesse erreicht.
Wird zu einer beliebigen Zeit eine Messung der bereits zugeteilten Anteile der Prozesse durchgeführt, sieht es tatsächlich so aus, als wür\-den alle Prozesse ihr Quantum gleichzeitig verbrauchen.
Allerdings hat diese Methode eine erheblichen Nachteil. Ein einziger Umschalt\-vorgang be\-nötigt selbst z.B. durch Ein- und Auslagerung der verschieden Daten im Speicher, wieder einen großen Teil der Prozessorleistung. Dadurch entsteht ein sehr schlechtes Verwaltungs- zu Verarbeitungs\-verhält\-nis und somit ist der Scheduler sehr uneffizient. Damit es nicht zu dieser Problematik beim CF-Scheduler kommen kann, wird eine minimale Zeitscheibe festgelegt. Diese minimale Zeitscheibe wird im Kernel als \textit{sysctl\_sched\_min\_granu\-larity} bezeichnet \cite{paperfairness}.
Somit wird an dieser Stelle sichergestellt, das der Verwaltungsaufwand zum Umschalten der Prozesse die Bearbeitungszeit der Prozesse im Prozessor nicht übersteigt.


%Mit dem CF-Scheduler muss nun eine Umgebung geschaffen werden, welche stark an der des idealen Multitasking-Prozessor anlehnt und wiederum aber auch die Effizienz zur Ausnutzung der Prozessorressource in einen akzeptablen Bereich bewegt.
Anders als bei den prioritäts\-bestim\-mten Scheduler, welche über Zeitscheiben und Warte\-schlan\-gen die Prioritäten verwalten, berechnet der CF-Scheduler die Zuteilung im Bezug zu allen anderen Prozessen, welche sich in der entsprechenden Warteschlange des Prozessors befinden. Der  \textit{nice}-Wert, welcher bereits in älteren Scheduler\-ver\-fahren für die Erstellung der Zeitscheiben zuständig war, wird jetzt verwendet, um den Prozessen ein Gewicht zuzuordnen. Ist der  \textit{nice}-Wert hoch, was eine niedrige Priorität bedeutet, so bekommt der Prozess auch ein niedriges Gewicht zugeteilt. Andersherum bekommt der Prozess ein hohes Gewicht, wenn der  \textit{nice}-Wert niedrig ist.

Mit Hilfe dieses Gewichtes wird dann das  Completely-Fair-Prinzip [s. Kapitel \ref{s:fair}] angewendet. 

Analog der Formel \ref{eq:perfect_fairness} wird zunächst mit Hilfe des ermittelten Gewichtes und der zu berechneten  Periode eine ideale Zeitscheibe errechnet. Dies geschieht nach \cite{paperfairness} mit folgender Formel:  

\begin{equation}
slice = \frac{se\rightarrow load.weight}{cfs\_rq\rightarrow load.weight} * period
\label{eq:slice}
\end{equation}

Hierbei ist \textit{se$\rightarrow$load.weight} das Gewicht des Prozesses aus dem entsprechendem \textit{nice}-Wert, welches durch ein von dem Kernel bereit gestelltes Array \texttt{prio\_to\_weight[]} ermittelt wird. In \cite{nikita} wird der Inhalt des Arrays mit folgenden Werten angegeben:

\begin {table}[h]
\begin{center}
\begin{tabular}{r|rrrrr}
 &	\multicolumn{5}{c}{\textit{Gewichte}} \\
	\hline\hline
	\\[\dimexpr-\normalbaselineskip+2pt]
	\textit{nice} & &+1	&	+2	& +3	& +4	\\
	\hline
    \\[\dimexpr-\normalbaselineskip+2pt]
	-20	&	88761	&	71755	&	56483	&	46273	&	36291	\\
	-15	&	29154 	&	23254 	&	18705 	&	14949 	&	11916	\\
	-10	&	9548	&	7620	&	6100	&	4904	&	3906	\\
	-5 	&	3121 	&	2501 	&	1991 	&	1586 	&	1277	\\
	0	&	1024 	&	820		&	655		&	526		&	423		\\
	5 	&	335 	&	272		& 	215		&	172		&	137		\\
	10	&	110		&	87 		&	70 		&	56 		&	45		\\
	15 	&	36 		&	29 		&	23 		&	18 		&	15	 	\\		
\end{tabular}
\caption {\textit{nice}-Wert zu Gewicht} \label{tab:nice2weight} 
\end{center}
\end{table}

   
Die Variable \textit{cfs\_rq$\rightarrow$load.weight} ist die Summe aller Gewichte der momentan aktiven Prozesse der Warte\-schlan\-ge.
\textit{period} ist der \glqq Zeitschlitz\grqq{}, für welchen eine Bewertung mit Basis auf die idealen Zeitscheiben der aktuellen Prozesse vorgenommen werden soll. Dieser Wert ist nicht konstant und einstellbar. Erreicht z.B. die Anzahl der lauf\-fähigen Prozesse eine kritische Grenze, so muss der Wert von \textit{period} erhöht werden. 
Diese Grenze wird im Kernel mit Hilfe der Variable \textit{nr\_latency} ermittelt. Diese Variable setzt sich aus dem Verhätlnis von \textit{period} und der minmalen Zeitscheibe zusammen \cite{paperfairness}.

\begin{equation}
nr\_latency = \frac{sysctl\_sched\_latency}{sysctl\_sched\_min\_granularity}
\label{eq:nr_latency}
\end{equation}

Somit gibt die Variable \textit{nr\_latency} die maximal mögliche Anzahl von Prozessen mit gegebenen Parametern vor. Über\-steigt nun die Anzahl der aktuell lauffähigen Prozesse diesen Wert, so muss der Wert von \textit{period}, bzw. in Formel \ref{eq:nr_latency} ensprechend \textit{sysctl\_sched\_latency}, erhöht werden.

Im anschließendem Schritt soll eine faire Auswahl auf den nächsten ausführbaren Prozess getroffen werden. Dies geschieht mit einer weiteren Bewertung der Prozesse im Bezug zu ihrer bereits ausgeführten Zeit. 
Dazu dient im Algorithmus die Variable \textit{virtual runtime}. In \cite{mjones} wird die \textit{virtual runtime} definiert als Menge der CPU-Zeit, die einer gewissen Aufgabe zugeordnet worden ist. Umso kleiner der Wert für \textit{virtual runtime} ist, desto höhere ist die Dringlichkeit dieser Aufgabe den Prozessor für sich zugewiesen zu bekommen. Ebenso beschreibt \cite{mjones} die Funktionalität von CFS, dass eine gewisse \textit{Sleeper-Fairness} implementiert ist: Aufgaben, die zu einem Zeitpunkt nicht lauffähig sind (z.B. beim Warten auf I/O"--Operationen) erhalten einen vergleichbaren Anteil am Prozessor, wenn sie diesen benö"-tigen.\\
Die \textit{virtual runtime}-Variable wird aus dem Verhältnis von bereits absolvierter Zeit zu dem ermitteltem Gewicht des Prozesses gebildet und ist für die Dauer der Aus\-führungs\-zeit für jeden Prozess ständig steigend \cite{rlove}. 
Nach \cite{paperfairness} wird \textit{virtual runtime} mit folgender Formel ermittelt:

\begin{multline}
vruntime \mathrel{+}= \frac{delta\_exec}{se\rightarrow load.weight} * NICE\_0\_LOAD \\ = \frac{period}{cfs\_rq\rightarrow load.weight} * NICE\_0\_LOAD
\label{eq:vruntime}
\end{multline}

Hierbei stellt \textit{delta\_exec} die bereits ausgeführte Zeit der jeweiligen Prozesses dar und \textit{NICE\_0\_LOAD} ist der Einheitswert der Gewichte, welcher das Gewicht des \textit{nice}-Wertes 0 darstellt.  
%welcher aus einer statischen 10-bit Dualzahl besteht $(2^{10}=1024)$ \cite{paperfairness}. 
Mit Hilfe des ersten Terms aus Formel \ref{eq:vruntime} wird die aktuelle virtuelle Laufzeit des jeweiligen Prozesses bestimmt. Der zweite Term dient zur Bestimmung der allgemeinen virtuelle Laufzeit, welche jeder Prozess nach Ablauf der Periodenzeit \textit{period} für diesen Zeitabschnitt erreicht haben soll. Dieser Wert soll nach Ablauf der Periodenzeit für alle Prozess gleich sein.

Mit dieser neuen Variablen können nun die Prozesse entsprechend ihrer Laufzeit und ihrem Gewicht bewertet und eine Rangfolge erstellt werden. Dazu wird an dieser Stelle der Rot-Schwarz-Baum [s.Kapitel \ref{s:rb_tree}] verwendet. Die Prozesse werden nach ihrem \textit{virtual runtime}-Wert in den Baum einsortiert. Dabei steht der Prozess mit der kleinsten \textit{virtual runtime} am weitesten links und kann nun durch den Scheduler ohne lange Suchzeiten ermittelt und als nächster auszuführender Prozess ausgewählt werden. 

Stehen zum Beispiel drei lauffähige Prozesse  mit \textit{nice}-Werten $0$, $1$ und $2$ und entsprechenden Gewichten von $1024$, $820$ und $655$ in einer Warteschlange für einen Prozessor.
Dann ergeben sich die idealen Zeitscheiben bei einer Periode von 20ms mit Formel \ref{eq:slice} zu $8.2ms$, $6.6ms$ und $5.2ms$. Ermittelt man nun dazu passend die \textit{virtual runtime}-Werte und zwar so, dass jeder Prozess seine Zuteilung für diese Periode vollständig ausgenutzt hat, so wird ersichtlich, dass alle Prozesse nun den gleichen \textit{virtual runtime}-Wert von ca. $8*10^{-6}$ besitzen. Damit wird eine faire Aufteilung mit Be\-rück\-sichtigung der \glqq Prioritäten\grqq{} gewährt.

%Jeder Prozess er\-hält eine Zeitscheibe, welche proportional zum eigenen Gewicht im Verhältnis zu den Gewichten aller Prozesse ist. Die Wahl des nächstes Prozesses fällt immer auf den Prozess, welcher bis zu diesem Zeitpunkt die geringste Zuteilung des Prozessors erhalten hat.
%Zur Berechnung einer Zeitscheibe, setzt der CF-Scheduler eine sogenannte „targeted latency“. Diese stellt einen Richtwert für die verfügbare Zeit aller anstehenden Prozesse dar, welcher äquivalent im perfekten Multitasking erreicht würde.

%Wenn zum Beispiel eine „targeted latency“ von 20ms errechnet wird und zwei Prozesse mit dem gleichen  \textit{nice}-Wert in der Warteschlange stehen, wird jedem Prozess eine Zuteilung von 10ms gewährt.

%Ein Problem ergibt sich bei dieser Anwendung, wenn die Anzahl der wartenden Prozesse gegen unendlich läuft. Damit würde die zugewiesene Zeit gegen Null laufen und es würde kein Prozess mehr die Berechtigung einer Zuteilung erhalten. Um dieses Problem zu umgehen, wird eine minimale Granulität eingeführt ,welche normalerweise mit einer Millisekunde gewählt wird. Das heißt jeder Prozess erhält immer mindestens eine Zuteilung von einer Millisekunde, egal wie groß die Menge der anstehenden Prozesse zu diesem Zeitpunkt ist. Dadurch wird allerdings das „faire“ Verhalten des Schedulers beeinträchtigt. 

%Auch findet eine weitere Unterscheidung zur Nutzung der  \textit{nice}-Wert statt. Wurde zuvor der absolute  \textit{nice}-Wert für eine Prioritätsermittlung benutzt, so spielt jetzt nur noch der relative Abstand zum nächsten  \textit{nice}-Wert eine Rolle.

%Ein passendes Beispiel ist in \cite{rlove} illustriert. Gegeben ist ein Zustand mit zwei Prozessen. Ein Prozess hat den  \textit{nice}-Wert 0, der andere den  \textit{nice}-Wert 5. Damit würde sich eine Prozessorzuteilzeit von 15ms für den Prozess mit  \textit{nice}-Wert 0 und eine Zuteilzeit von 5ms für den Prozess mit  \textit{nice}-Wert 5 ergeben.
%Im Vergleich dazu hätte man einen weiteren Zustand mit wiederum 2 Prozessen, aber dieses mal mit den  \textit{nice}-Werten 10 und 15. Hier würde das selbe Ergebnis mit 15ms und 5ms zustande kommen. Damit wird gezeigt, dass die Höhe des  \textit{nice}-Wertes nur noch die geometrische Differenz ändert.

%Anhand dieser Erläuterung kann gesehen werden, dass der CF-Scheduler nur eine Annäherung an ein perfektes faires Scheduling erreicht. Das große Problem der CF-Scheduler ist eine übermäßige Menge an Prozessen. Wird diese Menge in einem gewissen Rahmen gehalten, so kann der CF-Scheduler das  completely-fair -Prinzip gut erreichen. 
